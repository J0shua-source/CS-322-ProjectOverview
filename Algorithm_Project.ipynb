{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5d43297c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# some useful mysklearn package import statements and reloads\n",
    "import importlib\n",
    "\n",
    "import mysklearn.myutils\n",
    "importlib.reload(mysklearn.myutils)\n",
    "import mysklearn.myutils as myutils\n",
    "\n",
    "# uncomment once you paste your mypytable.py into mysklearn package\n",
    "import mysklearn.mypytable\n",
    "importlib.reload(mysklearn.mypytable)\n",
    "from mysklearn.mypytable import MyPyTable \n",
    "\n",
    "# uncomment once you paste your myclassifiers.py into mysklearn package\n",
    "import mysklearn.myclassifiers\n",
    "importlib.reload(mysklearn.myclassifiers)\n",
    "from mysklearn.myclassifiers import MyDecisionTreeClassifier\n",
    "\n",
    "import mysklearn.myevaluation\n",
    "importlib.reload(mysklearn.myevaluation)\n",
    "import mysklearn.myevaluation as myevaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "099db1d4",
   "metadata": {},
   "source": [
    "# Bitcoin Price Direction Prediction \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "eeccd4e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from mysklearn.myclassifiers import MyDecisionTreeClassifier\n",
    "from mysklearn.myevaluation import (\n",
    "    stratified_kfold_split, \n",
    "    confusion_matrix, \n",
    "    accuracy_score,\n",
    "    binary_precision_score, \n",
    "    binary_recall_score, \n",
    "    binary_f1_score\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f922f69",
   "metadata": {},
   "source": [
    "## Step 1: Load and Examine the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "307406b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Shape:\n",
      "  Rows: 1074\n",
      "  Columns: 28\n",
      "\n",
      "Column Headers:\n",
      "['Unnamed: 0', 'timestamp', 'open', 'high', 'low', 'close', 'volume', 'datetime_utc', 'merge_date', 'domestic_series', 'federal_financing_bank', 'foreign_series', 'government_account_series', 'government_account_series_inflation_securities', 'special_purpose_vehicle', 'state_and_local_government_series', 'total_interest-bearing_debt', 'total_marketable', 'total_non-marketable', 'treasury_bills', 'treasury_bonds', 'treasury_floating_rate_notes_(frn)', 'treasury_inflation-protected_securities_(tips)', 'treasury_notes', 'united_states_savings_inflation_securities', 'united_states_savings_securities', 'weighted_sentiment', 'sentiment_missing']\n",
      "\n",
      "First 5 Rows:\n",
      "   Unnamed: 0      timestamp      open      high       low     close  \\\n",
      "0           0  1669852800000  17165.44  17317.80  16855.00  16980.08   \n",
      "1           1  1669939200000  16980.07  17108.25  16791.02  17094.71   \n",
      "2           2  1670025600000  17094.25  17158.42  16863.58  16888.53   \n",
      "3           3  1670112000000  16889.17  17199.99  16882.86  17108.90   \n",
      "4           4  1670198400000  17108.90  17424.59  16865.22  16966.05   \n",
      "\n",
      "         volume               datetime_utc  merge_date  domestic_series  ...  \\\n",
      "0  31798.991518  2022-12-01 00:00:00+00:00  2022-12-01            7.577  ...   \n",
      "1  23096.436867  2022-12-02 00:00:00+00:00  2022-12-02            7.577  ...   \n",
      "2  14081.450672  2022-12-03 00:00:00+00:00  2022-12-03            7.577  ...   \n",
      "3  16961.108288  2022-12-04 00:00:00+00:00  2022-12-04            7.577  ...   \n",
      "4  33618.451090  2022-12-05 00:00:00+00:00  2022-12-05            7.577  ...   \n",
      "\n",
      "   total_non-marketable  treasury_bills  treasury_bonds  \\\n",
      "0                 2.135           3.456           3.012   \n",
      "1                 2.135           3.456           3.012   \n",
      "2                 2.135           3.456           3.012   \n",
      "3                 2.135           3.456           3.012   \n",
      "4                 2.135           3.456           3.012   \n",
      "\n",
      "   treasury_floating_rate_notes_(frn)  \\\n",
      "0                               4.104   \n",
      "1                               4.104   \n",
      "2                               4.104   \n",
      "3                               4.104   \n",
      "4                               4.104   \n",
      "\n",
      "   treasury_inflation-protected_securities_(tips)  treasury_notes  \\\n",
      "0                                           0.487            1.68   \n",
      "1                                           0.487            1.68   \n",
      "2                                           0.487            1.68   \n",
      "3                                           0.487            1.68   \n",
      "4                                           0.487            1.68   \n",
      "\n",
      "   united_states_savings_inflation_securities  \\\n",
      "0                                      10.148   \n",
      "1                                      10.148   \n",
      "2                                      10.148   \n",
      "3                                      10.148   \n",
      "4                                      10.148   \n",
      "\n",
      "   united_states_savings_securities  weighted_sentiment  sentiment_missing  \n",
      "0                             2.694            0.408548                  0  \n",
      "1                             2.694            0.136171                  0  \n",
      "2                             2.694           -0.347766                  0  \n",
      "3                             2.694            0.502235                  0  \n",
      "4                             2.694            0.326272                  0  \n",
      "\n",
      "[5 rows x 28 columns]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load the bitcoin sentiment dataset\n",
    "df = pd.read_csv('input_data/bitcoin_sentiment.csv')\n",
    "\n",
    "# Print dataset shape\n",
    "print(\"Dataset Shape:\")\n",
    "print(f\"  Rows: {df.shape[0]}\")\n",
    "print(f\"  Columns: {df.shape[1]}\")\n",
    "print()\n",
    "\n",
    "\n",
    "# Print headers (column names)\n",
    "print(\"Column Headers:\")\n",
    "print(df.columns.tolist())\n",
    "print()\n",
    "\n",
    "# Print first few rows\n",
    "print(\"First 5 Rows:\")\n",
    "print(df.head())\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b864e30e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label Distribution ('close'):\n",
      "0        16980.08\n",
      "1        17094.71\n",
      "2        16888.53\n",
      "3        17108.90\n",
      "4        16966.05\n",
      "          ...    \n",
      "1069    101468.15\n",
      "1070    103869.00\n",
      "1071    101290.50\n",
      "1072    103284.27\n",
      "1073    102249.20\n",
      "Name: close, Length: 1074, dtype: float64\n",
      "\n",
      "Label Proportions:\n",
      "0        16980.08\n",
      "1        17094.71\n",
      "2        16888.53\n",
      "3        17108.90\n",
      "4        16966.05\n",
      "          ...    \n",
      "1069    101468.15\n",
      "1070    103869.00\n",
      "1071    101290.50\n",
      "1072    103284.27\n",
      "1073    102249.20\n",
      "Name: close, Length: 1074, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Print label distribution \n",
    "label_column = df.columns[5]\n",
    "print(f\"Label Distribution ('{label_column}'):\")\n",
    "print(df[label_column])\n",
    "print()\n",
    "print(\"Label Proportions:\")\n",
    "print(df[label_column])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ec9188f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weighted Sentiment Statistics:\n",
      "count    1074.000000\n",
      "mean        0.347973\n",
      "std         0.274657\n",
      "min        -0.749771\n",
      "25%         0.171151\n",
      "50%         0.376796\n",
      "75%         0.540075\n",
      "max         0.952912\n",
      "Name: weighted_sentiment, dtype: float64\n",
      "\n",
      "No missing values found in the dataset.\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Checking for rows where 'sentiment_missing' != 0:\n",
      "No rows with sentiment_missing != 0 found.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Examine the weighted_sentiment column more closely\n",
    "print(\"Weighted Sentiment Statistics:\")\n",
    "print(df['weighted_sentiment'].describe())\n",
    "print()\n",
    "\n",
    "# Check for missing values\n",
    "if df.isnull().values.any():\n",
    "    print(\"Missing Values per Column:\")\n",
    "    print(df.isnull().sum())\n",
    "else:\n",
    "    print(\"No missing values found in the dataset.\")\n",
    "print()\n",
    "\n",
    "print(\"-\" * 70)\n",
    "print()\n",
    "\n",
    "# Check sentiment_missing column values for anything other than zero\n",
    "print(\"Checking for rows where 'sentiment_missing' != 0:\")\n",
    "if (df['sentiment_missing'] != 0).any():\n",
    "    print(df[df['sentiment_missing'] != 0])\n",
    "else:\n",
    "    print(\"No rows with sentiment_missing != 0 found.\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e219aa40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Label Distribution:\n",
      "sentiment_label\n",
      "Positive            949\n",
      "Negative/Neutral    125\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Label Proportions:\n",
      "sentiment_label\n",
      "Positive            0.883613\n",
      "Negative/Neutral    0.116387\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Total instances: 1074\n"
     ]
    }
   ],
   "source": [
    "# Create binary classification label from weighted_sentiment\n",
    "# Positive sentiment (>0) vs Negative/Neutral sentiment (<=0)\n",
    "df['sentiment_label'] = df['weighted_sentiment'].apply(lambda x: 'Positive' if x > 0 else 'Negative/Neutral')\n",
    "\n",
    "print(\"Classification Label Distribution:\")\n",
    "print(df['sentiment_label'].value_counts())\n",
    "print()\n",
    "print(\"Label Proportions:\")\n",
    "print(df['sentiment_label'].value_counts(normalize=True))\n",
    "print()\n",
    "print(f\"Total instances: {len(df)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "795ffb35",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7788d55a",
   "metadata": {},
   "source": [
    "## Step 2: Create Classification Label (Price Direction)\n",
    "\n",
    "Convert the continuous `close` price into a binary classification target by comparing each day's closing price with the previous day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9d22b012",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discretized Label Distribution (price_direction):\n",
      "price_direction\n",
      "Up      543\n",
      "Down    530\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Label Proportions:\n",
      "price_direction\n",
      "Up      0.506058\n",
      "Down    0.493942\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Total instances after discretization: 1073\n",
      "(Original: 1074, Removed first row: 1)\n"
     ]
    }
   ],
   "source": [
    "# Reload the original dataset\n",
    "df_original = pd.read_csv('input_data/bitcoin_sentiment.csv')\n",
    "\n",
    "# Create the discretized label by comparing close with previous day's close\n",
    "# First row will be dropped since there's no previous day\n",
    "df_original['price_direction'] = 'Down'  # Default value\n",
    "\n",
    "# Compare current close with previous close\n",
    "for i in range(1, len(df_original)):\n",
    "    if df_original.loc[i, 'close'] > df_original.loc[i-1, 'close']:\n",
    "        df_original.loc[i, 'price_direction'] = 'Up'\n",
    "    else:\n",
    "        df_original.loc[i, 'price_direction'] = 'Down'\n",
    "\n",
    "# Remove the first row (no previous day to compare)\n",
    "df_discretized = df_original.iloc[1:].copy()\n",
    "df_discretized = df_discretized.reset_index(drop=True)\n",
    "\n",
    "print(\"Discretized Label Distribution (price_direction):\")\n",
    "print(df_discretized['price_direction'].value_counts())\n",
    "print()\n",
    "print(\"Label Proportions:\")\n",
    "print(df_discretized['price_direction'].value_counts(normalize=True))\n",
    "print()\n",
    "print(f\"Total instances after discretization: {len(df_discretized)}\")\n",
    "print(f\"(Original: {len(df_original)}, Removed first row: 1)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d5e7ba5",
   "metadata": {},
   "source": [
    "## Step 3: Drop Unnecessary Features\n",
    "\n",
    "Remove temporal columns, identifiers, constant features, and **OHLC price features** to prevent data leakage.\n",
    "\n",
    "**Critical**: The `open`, `high`, `low`, and `close` features contain the current day's prices, which would leak information about the target variable (`price_direction`). Dropping them ensures legitimate prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "dbde3087",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset after dropping unnecessary columns:\n",
      "  Rows: 1073\n",
      "  Columns: 19\n",
      "  Dropped: ['Unnamed: 0', 'timestamp', 'datetime_utc', 'merge_date', 'sentiment_missing', 'domestic_series', 'open', 'high', 'low', 'close']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Drop unnecessary columns (temporal, IDs, constant features, and OHLC to prevent leakage)\n",
    "columns_to_drop = [\n",
    "    'Unnamed: 0', \n",
    "    'timestamp', \n",
    "    'datetime_utc', \n",
    "    'merge_date', \n",
    "    'sentiment_missing', \n",
    "    'domestic_series',\n",
    "    'open',   \n",
    "    'high', \n",
    "    'low',   \n",
    "    'close'   \n",
    "]\n",
    "df_clean = df_discretized.drop(columns=columns_to_drop)\n",
    "\n",
    "print(\"Dataset after dropping unnecessary columns:\")\n",
    "print(f\"  Rows: {df_clean.shape[0]}\")\n",
    "print(f\"  Columns: {df_clean.shape[1]}\")\n",
    "print(f\"  Dropped: {columns_to_drop}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcabbc58",
   "metadata": {},
   "source": [
    "## Step 4: Normalize Numeric Features\n",
    "\n",
    "Apply z-score normalization to scale all numeric features to mean=0 and std=1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f15787d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 18 numeric features to normalize\n",
      "\n",
      "Feature ranges before normalization:\n",
      "  volume: [1227.77, 65575.10]\n",
      "  federal_financing_bank: [2.39, 2.58]\n",
      "  foreign_series: [0.00, 7.31]\n",
      "  government_account_series: [2.13, 3.17]\n",
      "  government_account_series_inflation_securities: [0.99, 1.31]\n",
      "  special_purpose_vehicle: [2.89, 4.17]\n",
      "  state_and_local_government_series: [1.81, 3.85]\n",
      "  total_interest-bearing_debt: [2.22, 3.37]\n",
      "  total_marketable: [2.24, 3.42]\n",
      "  total_non-marketable: [2.13, 3.19]\n",
      "  treasury_bills: [3.46, 5.45]\n",
      "  treasury_bonds: [3.01, 3.34]\n",
      "  treasury_floating_rate_notes_(frn): [3.90, 5.54]\n",
      "  treasury_inflation-protected_securities_(tips): [0.49, 0.96]\n",
      "  treasury_notes: [1.68, 3.12]\n",
      "  united_states_savings_inflation_securities: [3.08, 10.15]\n",
      "  united_states_savings_securities: [2.69, 3.49]\n",
      "  weighted_sentiment: [-0.75, 0.95]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Identify numeric columns (exclude the label column 'price_direction')\n",
    "numeric_columns = df_clean.select_dtypes(include=[np.number]).columns.tolist()\n",
    "\n",
    "print(f\"Found {len(numeric_columns)} numeric features to normalize\")\n",
    "print()\n",
    "\n",
    "# Check the scale of numeric features before normalization\n",
    "print(\"Feature ranges before normalization:\")\n",
    "for col in numeric_columns[:18]:\n",
    "    print(f\"  {col}: [{df_clean[col].min():.2f}, {df_clean[col].max():.2f}]\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3a22575",
   "metadata": {},
   "source": [
    "### 4.1 Identify Numeric Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f0f62522",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Numeric features standardized (z-score normalization)\n",
      "\n",
      "Feature statistics after normalization:\n",
      "      volume  federal_financing_bank  foreign_series  \\\n",
      "mean    -0.0                     0.0             0.0   \n",
      "std      1.0                     1.0             1.0   \n",
      "\n",
      "      government_account_series  \\\n",
      "mean                        0.0   \n",
      "std                         1.0   \n",
      "\n",
      "      government_account_series_inflation_securities  special_purpose_vehicle  \\\n",
      "mean                                             0.0                     -0.0   \n",
      "std                                              1.0                      1.0   \n",
      "\n",
      "      state_and_local_government_series  total_interest-bearing_debt  \\\n",
      "mean                                0.0                         -0.0   \n",
      "std                                 1.0                          1.0   \n",
      "\n",
      "      total_marketable  total_non-marketable  treasury_bills  treasury_bonds  \\\n",
      "mean              -0.0                  -0.0             0.0             0.0   \n",
      "std                1.0                   1.0             1.0             1.0   \n",
      "\n",
      "      treasury_floating_rate_notes_(frn)  \\\n",
      "mean                                 0.0   \n",
      "std                                  1.0   \n",
      "\n",
      "      treasury_inflation-protected_securities_(tips)  treasury_notes  \\\n",
      "mean                                            -0.0             0.0   \n",
      "std                                              1.0             1.0   \n",
      "\n",
      "      united_states_savings_inflation_securities  \\\n",
      "mean                                         0.0   \n",
      "std                                          1.0   \n",
      "\n",
      "      united_states_savings_securities  weighted_sentiment  \n",
      "mean                               0.0                 0.0  \n",
      "std                                1.0                 1.0  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Apply z-score normalization: (x - mean) / std\n",
    "# This transforms each feature to have mean=0 and std=1\n",
    "\n",
    "df_normalized = df_clean.copy()\n",
    "\n",
    "for col in numeric_columns:\n",
    "    mean = df_normalized[col].mean()\n",
    "    std = df_normalized[col].std()\n",
    "    \n",
    "    # Avoid division by zero for constant columns\n",
    "    if std > 0:\n",
    "        df_normalized[col] = (df_normalized[col] - mean) / std\n",
    "    else:\n",
    "        print(f\"Warning: {col} has std=0, skipping normalization\")\n",
    "\n",
    "print(\"✓ Numeric features standardized (z-score normalization)\")\n",
    "print()\n",
    "\n",
    "# Verify normalization\n",
    "print(\"Feature statistics after normalization:\")\n",
    "print(df_normalized[numeric_columns].describe().loc[['mean', 'std']].round(6))\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c44cfe64",
   "metadata": {},
   "source": [
    "## Step 5: Discretize Features into Categorical Bins\n",
    "\n",
    "Convert normalized numeric features into categorical bins for entropy-based decision tree classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c6df99d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discretizing numeric features into 5 categorical bins...\n",
      "Bins: VeryLow, Low, Medium, High, VeryHigh\n",
      "\n",
      "Warning: Could not discretize 'federal_financing_bank': Bin labels must be one fewer than the number of bin edges\n",
      "Warning: Could not discretize 'foreign_series': Bin labels must be one fewer than the number of bin edges\n",
      "Skipped 2 columns: ['federal_financing_bank', 'foreign_series']\n"
     ]
    }
   ],
   "source": [
    "# Discretize normalized numeric features into categorical bins\n",
    "# Using quantile-based binning (equal frequency bins)\n",
    "\n",
    "df_discretized_final = df_normalized.copy()\n",
    "\n",
    "# Define binning strategy: convert normalized values to 5 categories\n",
    "# Since normalized data has mean=0, std=1, we can use standard deviations as boundaries\n",
    "def discretize_normalized_feature(series, n_bins=5):\n",
    "    \"\"\"\n",
    "    Discretize a normalized feature into categorical bins.\n",
    "    Uses quantile-based binning for equal frequency distribution.\n",
    "    \"\"\"\n",
    "    # Use pandas qcut for quantile-based binning\n",
    "    bins = pd.qcut(series, q=n_bins, labels=['VeryLow', 'Low', 'Medium', 'High', 'VeryHigh'], duplicates='drop')\n",
    "    return bins\n",
    "\n",
    "print(\"Discretizing numeric features into 5 categorical bins...\")\n",
    "print(\"Bins: VeryLow, Low, Medium, High, VeryHigh\")\n",
    "print()\n",
    "\n",
    "# Track which columns get discretized\n",
    "discretized_cols = []\n",
    "skipped_cols = []\n",
    "\n",
    "for col in numeric_columns:\n",
    "    try:\n",
    "        df_discretized_final[col] = discretize_normalized_feature(df_discretized_final[col])\n",
    "        discretized_cols.append(col)\n",
    "    except Exception as e:\n",
    "        # Some columns might have too few unique values to discretize\n",
    "        print(f\"Warning: Could not discretize '{col}': {e}\")\n",
    "        skipped_cols.append(col)\n",
    "\n",
    "print(f\"Skipped {len(skipped_cols)} columns: {skipped_cols}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a03af641",
   "metadata": {},
   "source": [
    "### 5.1 Apply Quantile-Based Binning (5 Equal-Frequency Bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "731d11d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Handling skipped columns with manual discretization:\n",
      "  federal_financing_bank: 5 unique values\n",
      "    Direct mapping: 5 unique values → Bank1-Bank5\n",
      "    Distribution: {'Bank1': 131, 'Bank2': 365, 'Bank3': 366, 'Bank4': 181, 'Bank5': 30}\n",
      "  foreign_series: 2 unique values\n",
      "✓ Skipped columns handled with custom discretization\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Handle columns that couldn't be discretized (too few unique values)\n",
    "# Convert them to categorical based on their actual unique values\n",
    "\n",
    "if skipped_cols:\n",
    "    print(\"Handling skipped columns with manual discretization:\")\n",
    "    for col in skipped_cols:\n",
    "        unique_vals = df_discretized_final[col].nunique()\n",
    "        print(f\"  {col}: {unique_vals} unique values\")\n",
    "        \n",
    "        # Apply custom discretization rules based on column name\n",
    "        if col == 'federal_financing_bank':\n",
    "            # Map 5 unique values directly to Bank1-Bank5 (preserves ordinality)\n",
    "            sorted_unique = sorted(df_normalized[col].unique())\n",
    "            bank_mapping = {val: f'Bank{i+1}' for i, val in enumerate(sorted_unique)}\n",
    "            df_discretized_final[col] = df_normalized[col].map(bank_mapping)\n",
    "            print(f\"    Direct mapping: {len(sorted_unique)} unique values → Bank1-Bank{len(sorted_unique)}\")\n",
    "            print(f\"    Distribution: {df_discretized_final[col].value_counts().sort_index().to_dict()}\")\n",
    "            \n",
    "        elif col == 'foreign_series':\n",
    "            # Bin into 0 or 1 (binary) using the original normalized data\n",
    "            df_discretized_final[col] = pd.cut(df_normalized[col], bins=2, labels=['0', '1'])\n",
    "            \n",
    "        elif unique_vals == 1:\n",
    "            # Constant feature\n",
    "            df_discretized_final[col] = 'Constant'\n",
    "            \n",
    "        elif unique_vals == 2:\n",
    "            df_discretized_final[col] = pd.cut(df_normalized[col], bins=2, labels=['Low', 'High'])\n",
    "            \n",
    "        elif unique_vals <= 5:\n",
    "            # For 3-5 unique values, map directly to preserve ordinal structure\n",
    "            sorted_unique = sorted(df_normalized[col].unique())\n",
    "            level_mapping = {val: f'Level_{i}' for i, val in enumerate(sorted_unique)}\n",
    "            df_discretized_final[col] = df_normalized[col].map(level_mapping)\n",
    "            \n",
    "        else:\n",
    "            # Default to 5 bins for columns with more unique values\n",
    "            df_discretized_final[col] = pd.qcut(df_normalized[col], q=5, \n",
    "                                                 labels=['VeryLow', 'Low', 'Medium', 'High', 'VeryHigh'], \n",
    "                                                 duplicates='drop')\n",
    "    \n",
    "    print(\"✓ Skipped columns handled with custom discretization\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "72ed849e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ All categorical features converted to 'category' dtype\n",
      "\n",
      "Sample of discretized features:\n",
      "     volume  federal_financing_bank  foreign_series government_account_series  \\\n",
      "0  VeryHigh                1.017022        2.816783                   VeryLow   \n",
      "1      High                1.017022        2.816783                   VeryLow   \n",
      "2      High                1.017022        2.816783                   VeryLow   \n",
      "3  VeryHigh                1.017022        2.816783                   VeryLow   \n",
      "4  VeryHigh                1.017022        2.816783                   VeryLow   \n",
      "5  VeryHigh                1.017022        2.816783                   VeryLow   \n",
      "6  VeryHigh                1.017022        2.816783                   VeryLow   \n",
      "7  VeryHigh                1.017022        2.816783                   VeryLow   \n",
      "8       Low                1.017022        2.816783                   VeryLow   \n",
      "9    Medium                1.017022        2.816783                   VeryLow   \n",
      "\n",
      "  government_account_series_inflation_securities special_purpose_vehicle  \\\n",
      "0                                        VeryLow                     Low   \n",
      "1                                        VeryLow                     Low   \n",
      "2                                        VeryLow                     Low   \n",
      "3                                        VeryLow                     Low   \n",
      "4                                        VeryLow                     Low   \n",
      "5                                        VeryLow                     Low   \n",
      "6                                        VeryLow                     Low   \n",
      "7                                        VeryLow                     Low   \n",
      "8                                        VeryLow                     Low   \n",
      "9                                        VeryLow                     Low   \n",
      "\n",
      "  state_and_local_government_series total_interest-bearing_debt  \\\n",
      "0                           VeryLow                     VeryLow   \n",
      "1                           VeryLow                     VeryLow   \n",
      "2                           VeryLow                     VeryLow   \n",
      "3                           VeryLow                     VeryLow   \n",
      "4                           VeryLow                     VeryLow   \n",
      "5                           VeryLow                     VeryLow   \n",
      "6                           VeryLow                     VeryLow   \n",
      "7                           VeryLow                     VeryLow   \n",
      "8                           VeryLow                     VeryLow   \n",
      "9                           VeryLow                     VeryLow   \n",
      "\n",
      "  total_marketable total_non-marketable treasury_bills treasury_bonds  \\\n",
      "0          VeryLow              VeryLow        VeryLow        VeryLow   \n",
      "1          VeryLow              VeryLow        VeryLow        VeryLow   \n",
      "2          VeryLow              VeryLow        VeryLow        VeryLow   \n",
      "3          VeryLow              VeryLow        VeryLow        VeryLow   \n",
      "4          VeryLow              VeryLow        VeryLow        VeryLow   \n",
      "5          VeryLow              VeryLow        VeryLow        VeryLow   \n",
      "6          VeryLow              VeryLow        VeryLow        VeryLow   \n",
      "7          VeryLow              VeryLow        VeryLow        VeryLow   \n",
      "8          VeryLow              VeryLow        VeryLow        VeryLow   \n",
      "9          VeryLow              VeryLow        VeryLow        VeryLow   \n",
      "\n",
      "  treasury_floating_rate_notes_(frn)  \\\n",
      "0                            VeryLow   \n",
      "1                            VeryLow   \n",
      "2                            VeryLow   \n",
      "3                            VeryLow   \n",
      "4                            VeryLow   \n",
      "5                            VeryLow   \n",
      "6                            VeryLow   \n",
      "7                            VeryLow   \n",
      "8                            VeryLow   \n",
      "9                            VeryLow   \n",
      "\n",
      "  treasury_inflation-protected_securities_(tips) treasury_notes  \\\n",
      "0                                        VeryLow        VeryLow   \n",
      "1                                        VeryLow        VeryLow   \n",
      "2                                        VeryLow        VeryLow   \n",
      "3                                        VeryLow        VeryLow   \n",
      "4                                        VeryLow        VeryLow   \n",
      "5                                        VeryLow        VeryLow   \n",
      "6                                        VeryLow        VeryLow   \n",
      "7                                        VeryLow        VeryLow   \n",
      "8                                        VeryLow        VeryLow   \n",
      "9                                        VeryLow        VeryLow   \n",
      "\n",
      "  united_states_savings_inflation_securities united_states_savings_securities  \\\n",
      "0                                   VeryHigh                          VeryLow   \n",
      "1                                   VeryHigh                          VeryLow   \n",
      "2                                   VeryHigh                          VeryLow   \n",
      "3                                   VeryHigh                          VeryLow   \n",
      "4                                   VeryHigh                          VeryLow   \n",
      "5                                   VeryHigh                          VeryLow   \n",
      "6                                   VeryHigh                          VeryLow   \n",
      "7                                   VeryHigh                          VeryLow   \n",
      "8                                   VeryHigh                          VeryLow   \n",
      "9                                   VeryHigh                          VeryLow   \n",
      "\n",
      "  weighted_sentiment price_direction  \n",
      "0                Low              Up  \n",
      "1            VeryLow            Down  \n",
      "2               High              Up  \n",
      "3             Medium            Down  \n",
      "4            VeryLow              Up  \n",
      "5             Medium            Down  \n",
      "6            VeryLow              Up  \n",
      "7           VeryHigh            Down  \n",
      "8                Low            Down  \n",
      "9             Medium            Down  \n",
      "\n",
      "\n",
      "Distribution of discretized 'volume':\n",
      "volume\n",
      "VeryLow     215\n",
      "Low         214\n",
      "Medium      215\n",
      "High        214\n",
      "VeryHigh    215\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Distribution of discretized 'weighted_sentiment':\n",
      "weighted_sentiment\n",
      "VeryLow     215\n",
      "Low         214\n",
      "Medium      215\n",
      "High        214\n",
      "VeryHigh    215\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Distribution of discretized 'federal_financing_bank':\n",
      "federal_financing_bank\n",
      "-1.645944    131\n",
      "-0.789991    365\n",
      " 0.712683    366\n",
      " 1.017022    181\n",
      " 1.968081     30\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Distribution of discretized 'foreign_series':\n",
      "foreign_series\n",
      "-0.354684    953\n",
      " 2.816783    120\n",
      "Name: count, dtype: int64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Convert all object columns to category dtype for better memory efficiency\n",
    "for col in df_discretized_final.columns:\n",
    "    if df_discretized_final[col].dtype == 'object':\n",
    "        df_discretized_final[col] = df_discretized_final[col].astype('category')\n",
    "\n",
    "print(\"✓ All categorical features converted to 'category' dtype\")\n",
    "print()\n",
    "\n",
    "# Verify discretization - check value distributions\n",
    "print(\"Sample of discretized features:\")\n",
    "print(df_discretized_final.head(10))\n",
    "print()\n",
    "\n",
    "# Show distribution for a few key features (updated - no OHLC features)\n",
    "sample_features = ['volume', 'weighted_sentiment', 'federal_financing_bank', 'foreign_series']\n",
    "for feature in sample_features:\n",
    "    if feature in df_discretized_final.columns:\n",
    "        print(f\"\\nDistribution of discretized '{feature}':\")\n",
    "        print(df_discretized_final[feature].value_counts().sort_index())\n",
    "\n",
    "print()\n",
    "# print(\"Data types after discretization:\")\n",
    "# print(df_discretized_final.dtypes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec9910ca",
   "metadata": {},
   "source": [
    "## Step 6: Save Preprocessed Dataset\n",
    "\n",
    "Export the final preprocessed dataset ready for classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a1cd84d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Final preprocessed dataset saved to: input_data/bitcoin_sentiment_discretized.csv\n",
      "  Total instances: 1073\n",
      "  Total features: 18\n",
      "  Label column: 'price_direction'\n",
      "\n",
      "\n",
      "Preprocessing Pipeline Summary:\n",
      "  1. Created binary label from daily price changes (Up/Down)\n",
      "  2. Dropped 10 unnecessary columns\n",
      "  3. Normalized 18 numeric features (z-score)\n",
      "  4. Discretized into categorical bins (VeryLow to VeryHigh)\n",
      "  5. Label distribution: {'Up': 543, 'Down': 530}\n",
      "  6. Dataset is now ready for MyRandomForestClassifier\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Save the final preprocessed dataset (ready for classification)\n",
    "output_file_final = 'input_data/bitcoin_sentiment_discretized.csv'\n",
    "df_discretized_final.to_csv(output_file_final, index=False)\n",
    "\n",
    "print(f\"✓ Final preprocessed dataset saved to: {output_file_final}\")\n",
    "print(f\"  Total instances: {len(df_discretized_final)}\")\n",
    "print(f\"  Total features: {len(df_discretized_final.columns) - 1}\")\n",
    "print(f\"  Label column: 'price_direction'\")\n",
    "print()\n",
    "print()\n",
    "print(\"Preprocessing Pipeline Summary:\")\n",
    "print(f\"  1. Created binary label from daily price changes (Up/Down)\")\n",
    "print(f\"  2. Dropped {len(columns_to_drop)} unnecessary columns\")\n",
    "print(f\"  3. Normalized {len(numeric_columns)} numeric features (z-score)\")\n",
    "print(f\"  4. Discretized into categorical bins (VeryLow to VeryHigh)\")\n",
    "print(f\"  5. Label distribution: {df_discretized_final['price_direction'].value_counts().to_dict()}\")\n",
    "print(f\"  6. Dataset is now ready for MyRandomForestClassifier\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6981575d",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Part 2: Random Forest Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a142c613",
   "metadata": {},
   "source": [
    "## Step 7: Load Preprocessed Data for Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ab2ad638",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessed Dataset Loaded:\n",
      "  Shape: (1073, 19)\n",
      "  Features: 18\n",
      "  Instances: 1073\n",
      "\n",
      "First 5 rows:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     volume federal_financing_bank  foreign_series government_account_series  \\\n",
      "0  VeryHigh                  Bank4               1                   VeryLow   \n",
      "1      High                  Bank4               1                   VeryLow   \n",
      "2      High                  Bank4               1                   VeryLow   \n",
      "3  VeryHigh                  Bank4               1                   VeryLow   \n",
      "4  VeryHigh                  Bank4               1                   VeryLow   \n",
      "\n",
      "  government_account_series_inflation_securities special_purpose_vehicle  \\\n",
      "0                                        VeryLow                     Low   \n",
      "1                                        VeryLow                     Low   \n",
      "2                                        VeryLow                     Low   \n",
      "3                                        VeryLow                     Low   \n",
      "4                                        VeryLow                     Low   \n",
      "\n",
      "  state_and_local_government_series total_interest-bearing_debt  \\\n",
      "0                           VeryLow                     VeryLow   \n",
      "1                           VeryLow                     VeryLow   \n",
      "2                           VeryLow                     VeryLow   \n",
      "3                           VeryLow                     VeryLow   \n",
      "4                           VeryLow                     VeryLow   \n",
      "\n",
      "  total_marketable total_non-marketable treasury_bills treasury_bonds  \\\n",
      "0          VeryLow              VeryLow        VeryLow        VeryLow   \n",
      "1          VeryLow              VeryLow        VeryLow        VeryLow   \n",
      "2          VeryLow              VeryLow        VeryLow        VeryLow   \n",
      "3          VeryLow              VeryLow        VeryLow        VeryLow   \n",
      "4          VeryLow              VeryLow        VeryLow        VeryLow   \n",
      "\n",
      "  treasury_floating_rate_notes_(frn)  \\\n",
      "0                            VeryLow   \n",
      "1                            VeryLow   \n",
      "2                            VeryLow   \n",
      "3                            VeryLow   \n",
      "4                            VeryLow   \n",
      "\n",
      "  treasury_inflation-protected_securities_(tips) treasury_notes  \\\n",
      "0                                        VeryLow        VeryLow   \n",
      "1                                        VeryLow        VeryLow   \n",
      "2                                        VeryLow        VeryLow   \n",
      "3                                        VeryLow        VeryLow   \n",
      "4                                        VeryLow        VeryLow   \n",
      "\n",
      "  united_states_savings_inflation_securities united_states_savings_securities  \\\n",
      "0                                   VeryHigh                          VeryLow   \n",
      "1                                   VeryHigh                          VeryLow   \n",
      "2                                   VeryHigh                          VeryLow   \n",
      "3                                   VeryHigh                          VeryLow   \n",
      "4                                   VeryHigh                          VeryLow   \n",
      "\n",
      "  weighted_sentiment price_direction  \n",
      "0                Low              Up  \n",
      "1            VeryLow            Down  \n",
      "2               High              Up  \n",
      "3             Medium            Down  \n",
      "4            VeryLow              Up  \n",
      "\n",
      "Data types:\n",
      "volume                                            object\n",
      "federal_financing_bank                            object\n",
      "foreign_series                                     int64\n",
      "government_account_series                         object\n",
      "government_account_series_inflation_securities    object\n",
      "special_purpose_vehicle                           object\n",
      "state_and_local_government_series                 object\n",
      "total_interest-bearing_debt                       object\n",
      "total_marketable                                  object\n",
      "total_non-marketable                              object\n",
      "treasury_bills                                    object\n",
      "treasury_bonds                                    object\n",
      "treasury_floating_rate_notes_(frn)                object\n",
      "treasury_inflation-protected_securities_(tips)    object\n",
      "treasury_notes                                    object\n",
      "united_states_savings_inflation_securities        object\n",
      "united_states_savings_securities                  object\n",
      "weighted_sentiment                                object\n",
      "price_direction                                   object\n",
      "dtype: object\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load the preprocessed dataset\n",
    "df_ready = pd.read_csv('input_data/bitcoin_sentiment_discretized.csv')\n",
    "\n",
    "print(\"Preprocessed Dataset Loaded:\")\n",
    "print(f\"  Shape: {df_ready.shape}\")\n",
    "print(f\"  Features: {df_ready.shape[1] - 1}\")\n",
    "print(f\"  Instances: {df_ready.shape[0]}\")\n",
    "print()\n",
    "\n",
    "# Display first few rows\n",
    "print(\"First 5 rows:\")\n",
    "print(df_ready.head())\n",
    "print()\n",
    "\n",
    "# Check data types\n",
    "print(\"Data types:\")\n",
    "print(df_ready.dtypes)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75f76f1a",
   "metadata": {},
   "source": [
    "## Step 8: Exploratory Data Analysis (EDA)\n",
    "\n",
    "### 8.1 Class Distribution Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1bba25ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "CLASS DISTRIBUTION ANALYSIS\n",
      "======================================================================\n",
      "\n",
      "Price Direction Distribution:\n",
      "  Down: 530 instances (49.39%)\n",
      "  Up: 543 instances (50.61%)\n",
      "\n",
      "Dataset is balanced\n",
      "Balance metric: 98.8% (100% = perfectly balanced)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Analyze class distribution\n",
    "print(\"=\"*70)\n",
    "print(\"CLASS DISTRIBUTION ANALYSIS\")\n",
    "print(\"=\"*70)\n",
    "print()\n",
    "\n",
    "label_counts = df_ready['price_direction'].value_counts()\n",
    "label_props = df_ready['price_direction'].value_counts(normalize=True)\n",
    "\n",
    "print(\"Price Direction Distribution:\")\n",
    "for label in sorted(label_counts.index):\n",
    "    count = label_counts[label]\n",
    "    prop = label_props[label]\n",
    "    print(f\"  {label}: {count} instances ({prop*100:.2f}%)\")\n",
    "\n",
    "print()\n",
    "balance_diff = abs(label_props.iloc[0] - 0.5)\n",
    "print(f\"Dataset is {'balanced' if balance_diff < 0.1 else 'imbalanced'}\")\n",
    "print(f\"Balance metric: {(1 - balance_diff*2)*100:.1f}% (100% = perfectly balanced)\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5915fef9",
   "metadata": {},
   "source": [
    "### 8.2 Feature Distribution Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5fbd2b9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "FEATURE DISTRIBUTION SUMMARY\n",
      "======================================================================\n",
      "\n",
      "Total features: 18\n",
      "\n",
      "\n",
      "volume:\n",
      "  Unique values: 5\n",
      "    High: 214 (19.9%)\n",
      "    Low: 214 (19.9%)\n",
      "    Medium: 215 (20.0%)\n",
      "    VeryHigh: 215 (20.0%)\n",
      "    VeryLow: 215 (20.0%)\n",
      "\n",
      "weighted_sentiment:\n",
      "  Unique values: 5\n",
      "    High: 214 (19.9%)\n",
      "    Low: 214 (19.9%)\n",
      "    Medium: 215 (20.0%)\n",
      "    VeryHigh: 215 (20.0%)\n",
      "    VeryLow: 215 (20.0%)\n",
      "\n",
      "federal_financing_bank:\n",
      "  Unique values: 5\n",
      "    Bank1: 131 (12.2%)\n",
      "    Bank2: 365 (34.0%)\n",
      "    Bank3: 366 (34.1%)\n",
      "    Bank4: 181 (16.9%)\n",
      "    Bank5: 30 (2.8%)\n",
      "\n",
      "foreign_series:\n",
      "  Unique values: 2\n",
      "    0: 953 (88.8%)\n",
      "    1: 120 (11.2%)\n",
      "\n",
      "total_marketable:\n",
      "  Unique values: 5\n",
      "    High: 214 (19.9%)\n",
      "    Low: 213 (19.9%)\n",
      "    Medium: 212 (19.8%)\n",
      "    VeryHigh: 192 (17.9%)\n",
      "    VeryLow: 242 (22.6%)\n",
      "\n",
      "✓ All 18 features are categorical (discretized)\n",
      "✓ No OHLC price features - prevents data leakage\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Analyze feature distributions\n",
    "print(\"=\"*70)\n",
    "print(\"FEATURE DISTRIBUTION SUMMARY\")\n",
    "print(\"=\"*70)\n",
    "print()\n",
    "\n",
    "feature_cols = [col for col in df_ready.columns if col != 'price_direction']\n",
    "\n",
    "print(f\"Total features: {len(feature_cols)}\")\n",
    "print()\n",
    "\n",
    "# Sample key features for detailed analysis (updated - no OHLC features)\n",
    "sample_features_eda = ['volume', 'weighted_sentiment', 'federal_financing_bank', 'foreign_series', 'total_marketable']\n",
    "\n",
    "for feature in sample_features_eda:\n",
    "    if feature in df_ready.columns:\n",
    "        print(f\"\\n{feature}:\")\n",
    "        print(f\"  Unique values: {df_ready[feature].nunique()}\")\n",
    "        value_counts = df_ready[feature].value_counts().sort_index()\n",
    "        for val, count in value_counts.items():\n",
    "            print(f\"    {val}: {count} ({count/len(df_ready)*100:.1f}%)\")\n",
    "\n",
    "print()\n",
    "print(f\"✓ All {len(feature_cols)} features are categorical (discretized)\")\n",
    "print(\"✓ No OHLC price features - prevents data leakage\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a468cf3",
   "metadata": {},
   "source": [
    "## Step 9: Prepare Data for Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e2860ff5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Preparation:\n",
      "  X shape: (1073, 18)\n",
      "  y shape: (1073,)\n",
      "\n",
      "  Number of features: 18\n",
      "  Number of instances: 1073\n",
      "\n",
      "Sample instance (first 5 features):\n",
      "  X[0][:5] = ['VeryHigh', 'Bank4', 1, 'VeryLow', 'VeryLow']\n",
      "  y[0] = Up\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Separate features (X) and label (y)\n",
    "X_data = df_ready.drop(columns=['price_direction']).values.tolist()\n",
    "y_data = df_ready['price_direction'].tolist()\n",
    "\n",
    "print(\"Data Preparation:\")\n",
    "print(f\"  X shape: ({len(X_data)}, {len(X_data[0])})\")\n",
    "print(f\"  y shape: ({len(y_data)},)\")\n",
    "print()\n",
    "print(f\"  Number of features: {len(X_data[0])}\")\n",
    "print(f\"  Number of instances: {len(X_data)}\")\n",
    "print()\n",
    "print(\"Sample instance (first 5 features):\")\n",
    "print(f\"  X[0][:5] = {X_data[0][:5]}\")\n",
    "print(f\"  y[0] = {y_data[0]}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ca7afa6",
   "metadata": {},
   "source": [
    "## Step 10: Train Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f54c2004",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "TRAINING RANDOM FOREST CLASSIFIER\n",
      "======================================================================\n",
      "\n",
      "Random Forest Configuration:\n",
      "  N (number of trees): 20\n",
      "  M (best trees for final ensemble): 7\n",
      "  F (features per split): 4 (sqrt of 18)\n",
      "  Bootstrap sampling: Yes\n",
      "  Test set size: 33% (stratified)\n",
      "\n",
      "Fitting Random Forest...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Training complete!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Import Random Forest Classifier\n",
    "from mysklearn.myclassifiers import MyRandomForestClassifier\n",
    "import math\n",
    "\n",
    "# Calculate F = sqrt(number of features)\n",
    "n_features_rf = len(X_data[0])\n",
    "F = int(math.sqrt(n_features_rf))\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"TRAINING RANDOM FOREST CLASSIFIER\")\n",
    "print(\"=\"*70)\n",
    "print()\n",
    "\n",
    "print(\"Random Forest Configuration:\")\n",
    "print(f\"  N (number of trees): 20\")\n",
    "print(f\"  M (best trees for final ensemble): 7\")\n",
    "print(f\"  F (features per split): {F} (sqrt of {n_features_rf})\")\n",
    "print(f\"  Bootstrap sampling: Yes\")\n",
    "print(f\"  Test set size: 33% (stratified)\")\n",
    "print()\n",
    "\n",
    "# Create and train Random Forest\n",
    "rf_classifier = MyRandomForestClassifier(\n",
    "    n_estimators=20,\n",
    "    max_features=F,\n",
    "    bootstrap=True,\n",
    "    random_state=42,\n",
    "    test_size=0.33\n",
    ")\n",
    "\n",
    "print(\"Fitting Random Forest...\")\n",
    "rf_classifier.fit(X_data, y_data)\n",
    "print(\"✓ Training complete!\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89889c7f",
   "metadata": {},
   "source": [
    "## Step 11: Evaluate Random Forest Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f1eefc86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "RANDOM FOREST PERFORMANCE SUMMARY\n",
      "======================================================================\n",
      "\n",
      "Random Forest with 20 trees\n",
      "Max features per tree: 4\n",
      "Bootstrap: True\n",
      "\n",
      "Dataset split:\n",
      "  Remainder set (training): 718 instances\n",
      "  Test set (stratified): 355 instances\n",
      "\n",
      "Feature Importances:\n",
      "  Feature att0: 0.0556\n",
      "  Feature att1: 0.0556\n",
      "  Feature att2: 0.0556\n",
      "  Feature att3: 0.0556\n",
      "  Feature att4: 0.0556\n",
      "  Feature att5: 0.0556\n",
      "  Feature att6: 0.0556\n",
      "  Feature att7: 0.0556\n",
      "  Feature att8: 0.0556\n",
      "  Feature att9: 0.0556\n",
      "  Feature att10: 0.0556\n",
      "  Feature att11: 0.0556\n",
      "  Feature att12: 0.0556\n",
      "  Feature att13: 0.0556\n",
      "  Feature att14: 0.0556\n",
      "  Feature att15: 0.0556\n",
      "  Feature att16: 0.0556\n",
      "  Feature att17: 0.0556\n",
      "\n",
      "Out-of-Bag Score (on remainder set): 0.7716\n",
      "Test Set Accuracy (stratified): 0.5014\n",
      "\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# Display Random Forest information and performance\n",
    "print(\"=\"*70)\n",
    "print(\"RANDOM FOREST PERFORMANCE SUMMARY\")\n",
    "print(\"=\"*70)\n",
    "print()\n",
    "\n",
    "rf_classifier.print_forest_info()\n",
    "\n",
    "print()\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65ae13a0",
   "metadata": {},
   "source": [
    "### 11.1 Detailed Test Set Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "233f2da8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Set Predictions Analysis:\n",
      "  Total test instances: 355\n",
      "\n",
      "Confusion Matrix:\n",
      "  Actual↓ / Predicted→\n",
      "             Down      Up\n",
      "    Down     105      70\n",
      "      Up     107      73\n",
      "\n",
      "Per-Class Performance:\n",
      "\n",
      "  Class 'Down':\n",
      "    True Positives:  105\n",
      "    False Positives: 107\n",
      "    False Negatives: 70\n",
      "    True Negatives:  73\n",
      "    Precision: 0.4953\n",
      "    Recall:    0.6000\n",
      "    F1-Score:  0.5426\n",
      "\n",
      "  Class 'Up':\n",
      "    True Positives:  73\n",
      "    False Positives: 70\n",
      "    False Negatives: 107\n",
      "    True Negatives:  105\n",
      "    Precision: 0.5105\n",
      "    Recall:    0.4056\n",
      "    F1-Score:  0.4520\n",
      "\n",
      "Overall Test Accuracy: 0.5014 (50.14%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Make predictions on the internal test set\n",
    "y_pred_test = rf_classifier.predict(rf_classifier.X_test_internal)\n",
    "y_true_test = rf_classifier.y_test_internal\n",
    "\n",
    "print(\"Test Set Predictions Analysis:\")\n",
    "print(f\"  Total test instances: {len(y_true_test)}\")\n",
    "print()\n",
    "\n",
    "# Calculate confusion matrix\n",
    "from mysklearn.myevaluation import confusion_matrix, accuracy_score\n",
    "\n",
    "# Get unique labels\n",
    "labels_rf = sorted(list(set(y_true_test)))\n",
    "\n",
    "# Create confusion matrix\n",
    "conf_matrix_rf = confusion_matrix(y_true_test, y_pred_test, labels=labels_rf)\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(f\"  Actual↓ / Predicted→\")\n",
    "print(f\"         \", end=\"\")\n",
    "for label in labels_rf:\n",
    "    print(f\"{label:>8}\", end=\"\")\n",
    "print()\n",
    "\n",
    "for i, actual_label in enumerate(labels_rf):\n",
    "    print(f\"  {actual_label:>6}\", end=\"\")\n",
    "    for j in range(len(labels_rf)):\n",
    "        print(f\"{conf_matrix_rf[i][j]:>8}\", end=\"\")\n",
    "    print()\n",
    "\n",
    "print()\n",
    "\n",
    "# Calculate metrics for each class\n",
    "print(\"Per-Class Performance:\")\n",
    "for i, label in enumerate(labels_rf):\n",
    "    tp = conf_matrix_rf[i][i]\n",
    "    fn = sum(conf_matrix_rf[i]) - tp\n",
    "    fp = sum(conf_matrix_rf[j][i] for j in range(len(labels_rf))) - tp\n",
    "    tn = sum(sum(row) for row in conf_matrix_rf) - tp - fn - fp\n",
    "    \n",
    "    precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "    recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "    f1 = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0\n",
    "    \n",
    "    print(f\"\\n  Class '{label}':\")\n",
    "    print(f\"    True Positives:  {tp}\")\n",
    "    print(f\"    False Positives: {fp}\")\n",
    "    print(f\"    False Negatives: {fn}\")\n",
    "    print(f\"    True Negatives:  {tn}\")\n",
    "    print(f\"    Precision: {precision:.4f}\")\n",
    "    print(f\"    Recall:    {recall:.4f}\")\n",
    "    print(f\"    F1-Score:  {f1:.4f}\")\n",
    "\n",
    "print()\n",
    "overall_acc = accuracy_score(y_true_test, y_pred_test)\n",
    "print(f\"Overall Test Accuracy: {overall_acc:.4f} ({overall_acc*100:.2f}%)\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb9c08e1",
   "metadata": {},
   "source": [
    "### 11.2 Prediction Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0d0c0fb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "SAMPLE PREDICTIONS (First 10 Test Instances)\n",
      "======================================================================\n",
      "\n",
      "Instance 1:\n",
      "  Actual: Down\n",
      "  Predicted: Down\n",
      "  Correct: ✓\n",
      "  Features:\n",
      "    volume: VeryLow\n",
      "    federal_financing_bank: Bank2\n",
      "    foreign_series: 0\n",
      "    government_account_series: Medium\n",
      "    government_account_series_inflation_securities: VeryHigh\n",
      "    special_purpose_vehicle: Low\n",
      "    state_and_local_government_series: High\n",
      "    total_interest-bearing_debt: High\n",
      "    total_marketable: High\n",
      "    total_non-marketable: Medium\n",
      "    treasury_bills: Low\n",
      "    treasury_bonds: VeryHigh\n",
      "    treasury_floating_rate_notes_(frn): Low\n",
      "    treasury_inflation-protected_securities_(tips): VeryHigh\n",
      "    treasury_notes: VeryHigh\n",
      "    united_states_savings_inflation_securities: VeryLow\n",
      "    united_states_savings_securities: Low\n",
      "    weighted_sentiment: VeryHigh\n",
      "\n",
      "Instance 2:\n",
      "  Actual: Up\n",
      "  Predicted: Down\n",
      "  Correct: ✗\n",
      "  Features:\n",
      "    volume: Medium\n",
      "    federal_financing_bank: Bank3\n",
      "    foreign_series: 0\n",
      "    government_account_series: Low\n",
      "    government_account_series_inflation_securities: VeryLow\n",
      "    special_purpose_vehicle: VeryHigh\n",
      "    state_and_local_government_series: Low\n",
      "    total_interest-bearing_debt: Low\n",
      "    total_marketable: Low\n",
      "    total_non-marketable: Low\n",
      "    treasury_bills: High\n",
      "    treasury_bonds: Low\n",
      "    treasury_floating_rate_notes_(frn): High\n",
      "    treasury_inflation-protected_securities_(tips): Low\n",
      "    treasury_notes: Low\n",
      "    united_states_savings_inflation_securities: High\n",
      "    united_states_savings_securities: Low\n",
      "    weighted_sentiment: Low\n",
      "\n",
      "Instance 3:\n",
      "  Actual: Down\n",
      "  Predicted: Down\n",
      "  Correct: ✓\n",
      "  Features:\n",
      "    volume: VeryLow\n",
      "    federal_financing_bank: Bank3\n",
      "    foreign_series: 0\n",
      "    government_account_series: Low\n",
      "    government_account_series_inflation_securities: VeryLow\n",
      "    special_purpose_vehicle: VeryHigh\n",
      "    state_and_local_government_series: Low\n",
      "    total_interest-bearing_debt: Low\n",
      "    total_marketable: Low\n",
      "    total_non-marketable: Low\n",
      "    treasury_bills: High\n",
      "    treasury_bonds: Low\n",
      "    treasury_floating_rate_notes_(frn): High\n",
      "    treasury_inflation-protected_securities_(tips): Low\n",
      "    treasury_notes: Low\n",
      "    united_states_savings_inflation_securities: High\n",
      "    united_states_savings_securities: Low\n",
      "    weighted_sentiment: VeryLow\n",
      "\n",
      "Instance 4:\n",
      "  Actual: Down\n",
      "  Predicted: Down\n",
      "  Correct: ✓\n",
      "  Features:\n",
      "    volume: VeryLow\n",
      "    federal_financing_bank: Bank1\n",
      "    foreign_series: 0\n",
      "    government_account_series: VeryHigh\n",
      "    government_account_series_inflation_securities: VeryHigh\n",
      "    special_purpose_vehicle: Low\n",
      "    state_and_local_government_series: High\n",
      "    total_interest-bearing_debt: VeryHigh\n",
      "    total_marketable: VeryHigh\n",
      "    total_non-marketable: VeryHigh\n",
      "    treasury_bills: VeryLow\n",
      "    treasury_bonds: VeryHigh\n",
      "    treasury_floating_rate_notes_(frn): Low\n",
      "    treasury_inflation-protected_securities_(tips): VeryHigh\n",
      "    treasury_notes: VeryHigh\n",
      "    united_states_savings_inflation_securities: VeryLow\n",
      "    united_states_savings_securities: Medium\n",
      "    weighted_sentiment: High\n",
      "\n",
      "Instance 5:\n",
      "  Actual: Up\n",
      "  Predicted: Down\n",
      "  Correct: ✗\n",
      "  Features:\n",
      "    volume: Medium\n",
      "    federal_financing_bank: Bank4\n",
      "    foreign_series: 1\n",
      "    government_account_series: VeryLow\n",
      "    government_account_series_inflation_securities: VeryLow\n",
      "    special_purpose_vehicle: Low\n",
      "    state_and_local_government_series: VeryLow\n",
      "    total_interest-bearing_debt: VeryLow\n",
      "    total_marketable: VeryLow\n",
      "    total_non-marketable: VeryLow\n",
      "    treasury_bills: VeryLow\n",
      "    treasury_bonds: VeryLow\n",
      "    treasury_floating_rate_notes_(frn): VeryLow\n",
      "    treasury_inflation-protected_securities_(tips): VeryLow\n",
      "    treasury_notes: VeryLow\n",
      "    united_states_savings_inflation_securities: VeryHigh\n",
      "    united_states_savings_securities: VeryLow\n",
      "    weighted_sentiment: VeryLow\n",
      "\n",
      "Instance 6:\n",
      "  Actual: Down\n",
      "  Predicted: Down\n",
      "  Correct: ✓\n",
      "  Features:\n",
      "    volume: Medium\n",
      "    federal_financing_bank: Bank3\n",
      "    foreign_series: 0\n",
      "    government_account_series: Medium\n",
      "    government_account_series_inflation_securities: Medium\n",
      "    special_purpose_vehicle: High\n",
      "    state_and_local_government_series: VeryHigh\n",
      "    total_interest-bearing_debt: Medium\n",
      "    total_marketable: Medium\n",
      "    total_non-marketable: Medium\n",
      "    treasury_bills: High\n",
      "    treasury_bonds: Medium\n",
      "    treasury_floating_rate_notes_(frn): VeryHigh\n",
      "    treasury_inflation-protected_securities_(tips): Medium\n",
      "    treasury_notes: Medium\n",
      "    united_states_savings_inflation_securities: High\n",
      "    united_states_savings_securities: VeryHigh\n",
      "    weighted_sentiment: Low\n",
      "\n",
      "Instance 7:\n",
      "  Actual: Up\n",
      "  Predicted: Down\n",
      "  Correct: ✗\n",
      "  Features:\n",
      "    volume: VeryLow\n",
      "    federal_financing_bank: Bank3\n",
      "    foreign_series: 0\n",
      "    government_account_series: Low\n",
      "    government_account_series_inflation_securities: VeryLow\n",
      "    special_purpose_vehicle: VeryHigh\n",
      "    state_and_local_government_series: Low\n",
      "    total_interest-bearing_debt: Low\n",
      "    total_marketable: Low\n",
      "    total_non-marketable: Low\n",
      "    treasury_bills: VeryHigh\n",
      "    treasury_bonds: Low\n",
      "    treasury_floating_rate_notes_(frn): Medium\n",
      "    treasury_inflation-protected_securities_(tips): Low\n",
      "    treasury_notes: Low\n",
      "    united_states_savings_inflation_securities: High\n",
      "    united_states_savings_securities: Low\n",
      "    weighted_sentiment: Low\n",
      "\n",
      "Instance 8:\n",
      "  Actual: Up\n",
      "  Predicted: Up\n",
      "  Correct: ✓\n",
      "  Features:\n",
      "    volume: Low\n",
      "    federal_financing_bank: Bank1\n",
      "    foreign_series: 0\n",
      "    government_account_series: Medium\n",
      "    government_account_series_inflation_securities: VeryHigh\n",
      "    special_purpose_vehicle: VeryLow\n",
      "    state_and_local_government_series: Medium\n",
      "    total_interest-bearing_debt: High\n",
      "    total_marketable: High\n",
      "    total_non-marketable: Medium\n",
      "    treasury_bills: VeryLow\n",
      "    treasury_bonds: VeryHigh\n",
      "    treasury_floating_rate_notes_(frn): VeryLow\n",
      "    treasury_inflation-protected_securities_(tips): VeryHigh\n",
      "    treasury_notes: VeryHigh\n",
      "    united_states_savings_inflation_securities: VeryLow\n",
      "    united_states_savings_securities: Medium\n",
      "    weighted_sentiment: Low\n",
      "\n",
      "Instance 9:\n",
      "  Actual: Up\n",
      "  Predicted: Up\n",
      "  Correct: ✓\n",
      "  Features:\n",
      "    volume: Low\n",
      "    federal_financing_bank: Bank2\n",
      "    foreign_series: 0\n",
      "    government_account_series: High\n",
      "    government_account_series_inflation_securities: VeryHigh\n",
      "    special_purpose_vehicle: VeryLow\n",
      "    state_and_local_government_series: High\n",
      "    total_interest-bearing_debt: High\n",
      "    total_marketable: High\n",
      "    total_non-marketable: High\n",
      "    treasury_bills: Low\n",
      "    treasury_bonds: VeryHigh\n",
      "    treasury_floating_rate_notes_(frn): Low\n",
      "    treasury_inflation-protected_securities_(tips): VeryHigh\n",
      "    treasury_notes: VeryHigh\n",
      "    united_states_savings_inflation_securities: VeryLow\n",
      "    united_states_savings_securities: Low\n",
      "    weighted_sentiment: Low\n",
      "\n",
      "Instance 10:\n",
      "  Actual: Down\n",
      "  Predicted: Down\n",
      "  Correct: ✓\n",
      "  Features:\n",
      "    volume: VeryLow\n",
      "    federal_financing_bank: Bank3\n",
      "    foreign_series: 0\n",
      "    government_account_series: VeryLow\n",
      "    government_account_series_inflation_securities: VeryLow\n",
      "    special_purpose_vehicle: High\n",
      "    state_and_local_government_series: VeryLow\n",
      "    total_interest-bearing_debt: VeryLow\n",
      "    total_marketable: VeryLow\n",
      "    total_non-marketable: VeryLow\n",
      "    treasury_bills: Medium\n",
      "    treasury_bonds: VeryLow\n",
      "    treasury_floating_rate_notes_(frn): High\n",
      "    treasury_inflation-protected_securities_(tips): VeryLow\n",
      "    treasury_notes: VeryLow\n",
      "    united_states_savings_inflation_securities: High\n",
      "    united_states_savings_securities: VeryLow\n",
      "    weighted_sentiment: VeryLow\n",
      "\n",
      "Correct predictions: 178/355 (50.14%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check if Random Forest classifier has been trained\n",
    "try:\n",
    "    # Get predictions from the trained random forest classifier\n",
    "    y_pred_test = rf_classifier.predict(rf_classifier.X_test_internal)\n",
    "    y_true_test = rf_classifier.y_test_internal\n",
    "    \n",
    "    print(\"=\"*70)\n",
    "    print(\"SAMPLE PREDICTIONS (First 10 Test Instances)\")\n",
    "    print(\"=\"*70)\n",
    "    print()\n",
    "\n",
    "    feature_names_rf = [col for col in df_discretized_final.columns if col != 'price_direction']\n",
    "    \n",
    "    # Display first 10 predictions with feature details\n",
    "    for i in range(min(10, len(y_true_test))):\n",
    "        instance = rf_classifier.X_test_internal[i]\n",
    "        print(f\"Instance {i+1}:\")\n",
    "        print(f\"  Actual: {y_true_test[i]}\")\n",
    "        print(f\"  Predicted: {y_pred_test[i]}\")\n",
    "        print(f\"  Correct: {'✓' if y_true_test[i] == y_pred_test[i] else '✗'}\")\n",
    "        print(f\"  Features:\")\n",
    "        for j in range(len(instance)):\n",
    "            print(f\"    {feature_names_rf[j]}: {instance[j]}\")\n",
    "        print()\n",
    "\n",
    "    # Summary\n",
    "    correct_preds = sum(1 for t, p in zip(y_true_test, y_pred_test) if t == p)\n",
    "    print(f\"Correct predictions: {correct_preds}/{len(y_true_test)} ({correct_preds/len(y_true_test)*100:.2f}%)\")\n",
    "    print()\n",
    "    \n",
    "except NameError:\n",
    "    print(\"=\"*70)\n",
    "    print(\"ERROR: Random Forest Classifier Not Found\")\n",
    "    print(\"=\"*70)\n",
    "    print()\n",
    "    print(\"Please run the Random Forest training cells first (Step 10).\")\n",
    "    print(\"The classifier 'rf_classifier' needs to be created before running this cell.\")\n",
    "    print()\n",
    "    print(\"To fix this:\")\n",
    "    print(\"1. Navigate to 'Step 10: Train Random Forest Classifier'\")\n",
    "    print(\"2. Run that cell to create and train the classifier\")\n",
    "    print(\"3. Then come back and run this cell\")\n",
    "    print()\n",
    "    print(\"Stopping execution - classifier not available.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bcf5ee6",
   "metadata": {},
   "source": [
    "## Summary and Conclusions\n",
    "\n",
    "This notebook demonstrated a complete machine learning pipeline for Bitcoin price direction prediction:\n",
    "\n",
    "1. **Data Preprocessing**: Loaded raw Bitcoin sentiment data, created binary price direction labels, normalized features, and discretized into categorical bins\n",
    "2. **Data Leakage Prevention**: Dropped OHLC features (open, high, low, close) to ensure the model predicts legitimately using only volume, sentiment, and macroeconomic indicators\n",
    "3. **Random Forest Training**: Trained an ensemble of 20 decision trees with bootstrap sampling and random feature selection (F = √18 ≈ 4 features per split)\n",
    "4. **Evaluation**: Achieved test accuracy using stratified train/test split, with OOB score validation\n",
    "\n",
    "**Key Findings:**\n",
    "- Dataset is balanced (~50/50 Up/Down)\n",
    "- All numeric features successfully discretized into categorical bins\n",
    "- Random Forest uses stratified sampling to preserve class distribution\n",
    "- Model predicts price direction using legitimate features (no price leakage)\n",
    "- Features used: trading volume, sentiment analysis, and treasury/debt indicators\n",
    "\n",
    "**Data Integrity:**\n",
    "- ✓ No temporal leakage (OHLC prices removed)\n",
    "- ✓ Legitimate forecasting task (predict tomorrow using today's non-price data)\n",
    "- ✓ Model performance reflects true predictive capability"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
